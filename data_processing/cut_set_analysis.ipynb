{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "# Load the graph\n",
    "from xlron.environments.rsa import make_graph\n",
    "\n",
    "graph = make_graph(\"nsfnet\", topology_directory=\"/Users/michaeldoherty/git/XLRON/topologies\")\n",
    "\n",
    "# Make N x N numpy matrix where N is the number of nodes, with values 1/N\n",
    "traffic_matrix = np.full((len(graph.nodes), len(graph.nodes)), 1 / len(graph.nodes))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T14:51:14.624582Z",
     "start_time": "2024-05-25T14:51:14.617589Z"
    }
   },
   "cell_type": "code",
   "source": "node_cuts = nx.all_node_cuts(graph)",
   "id": "205cb4e2e421b684",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4, 6, 8}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-25T14:51:43.994449Z",
     "start_time": "2024-05-25T14:51:43.959817Z"
    }
   },
   "cell_type": "code",
   "source": "len(list(node_cuts))",
   "id": "a3639efc82ff852b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import networkx as nx\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "def find_all_cut_sets(G):\n",
    "    \"\"\"\n",
    "    Find all cut-sets of a graph G.\n",
    "    Returns a list of cut-sets, where each cut-set is represented as a set of edges.\n",
    "    \"\"\"\n",
    "    cut_sets = []\n",
    "    for i in range(1, len(G.nodes) // 2 + 1):\n",
    "        for subset in itertools.combinations(G.nodes, i):\n",
    "            complement = set(G.nodes) - set(subset)\n",
    "            if nx.is_connected(G.subgraph(subset)) and nx.is_connected(G.subgraph(complement)):\n",
    "                cut_set = set(nx.edge_boundary(G, subset))\n",
    "                cut_sets.append(cut_set)\n",
    "    return cut_sets\n",
    "\n",
    "def estimate_congestion_level(G, cut_set, traffic_matrix):\n",
    "    \"\"\"\n",
    "    Estimate the congestion level of a cut-set based on the traffic matrix.\n",
    "    Returns the ratio of the number of links in the cut-set to the expected number of lightpaths traversing the cut-set.\n",
    "    \"\"\"\n",
    "    subset = set(nx.node_connected_component(G.edge_subgraph(cut_set), next(iter(cut_set))[0]))\n",
    "    complement = set(G.nodes) - subset\n",
    "    expected_lightpaths = sum(traffic_matrix[i][j] for i in subset for j in complement)\n",
    "    return len(cut_set) / expected_lightpaths\n",
    "\n",
    "def estimate_capacity_upper_bound(G, traffic_matrix, num_wavelengths, num_cut_sets):\n",
    "    \"\"\"\n",
    "    Estimate the capacity upper bound using the cut-set analysis method.\n",
    "    Returns the estimated upper bound on the number of lightpaths that can be accommodated.\n",
    "    \"\"\"\n",
    "    cut_sets = find_all_cut_sets(G)\n",
    "    congestion_levels = [(cut_set, estimate_congestion_level(G, cut_set, traffic_matrix)) for cut_set in cut_sets]\n",
    "    congestion_levels.sort(key=lambda x: x[1])\n",
    "    \n",
    "    lightpaths = 0\n",
    "    wavelength_availability = {link: set(range(num_wavelengths)) for link in G.edges}\n",
    "    \n",
    "    while True:\n",
    "        src, dst = random.choices(list(G.nodes), k=2)\n",
    "        cut_sets_to_traverse = [cut_set for cut_set, _ in congestion_levels[:num_cut_sets] if \n",
    "                                any(src in set(nx.node_connected_component(G.edge_subgraph(cut_set), node)) and \n",
    "                                    dst in set(G.nodes) - set(nx.node_connected_component(G.edge_subgraph(cut_set), node))\n",
    "                                    for node in cut_set)]\n",
    "        \n",
    "        if not cut_sets_to_traverse:\n",
    "            lightpaths += 1\n",
    "            continue\n",
    "        \n",
    "        available_wavelengths = set.intersection(*(wavelength_availability[link] for cut_set in cut_sets_to_traverse for link in cut_set))\n",
    "        \n",
    "        if not available_wavelengths:\n",
    "            break\n",
    "        \n",
    "        wavelength = available_wavelengths.pop()\n",
    "        for cut_set in cut_sets_to_traverse:\n",
    "            for link in cut_set:\n",
    "                wavelength_availability[link].remove(wavelength)\n",
    "        \n",
    "        lightpaths += 1\n",
    "    \n",
    "    return lightpaths\n",
    "\n",
    "# Example usage\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([('A', 'B'), ('B', 'C'), ('C', 'D'), ('D', 'E'), ('E', 'F'), ('A', 'F')])\n",
    "\n",
    "traffic_matrix = {node: {other: random.randint(1, 10) for other in G.nodes if other != node} for node in G.nodes}\n",
    "\n",
    "num_wavelengths = 10\n",
    "num_cut_sets = 3\n",
    "\n",
    "upper_bound = estimate_capacity_upper_bound(G, traffic_matrix, num_wavelengths, num_cut_sets)\n",
    "print(f\"Estimated capacity upper bound: {upper_bound} lightpaths\")"
   ],
   "id": "effd11ded13a09d2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
