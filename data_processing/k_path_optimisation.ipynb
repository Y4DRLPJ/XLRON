{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7da4d3f234d5675",
   "metadata": {},
   "source": [
    "# Evaluate heuristics with different values of k to compute k-shortest paths\n",
    "Evaluate heuristics on different topologies for a range of k.\n",
    "Can be evaluated for fixed length episodes or episodes that end on first blocking event."
   ]
  },
  {
   "cell_type": "code",
   "id": "3053c98446be7eb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T14:43:02.456040Z",
     "start_time": "2024-09-05T14:43:02.450590Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "# Run the train script for each value of k\n",
    "root = \"/home/uceedoh\"\n",
    "data_directory = f\"{root}/git/XLRON/data\"\n",
    "data_directory = f\"{root}/git/XLRON/data/heuristic_benchmarks\"\n",
    "script_path = f\"{root}/git/XLRON/xlron/train/train.py\"\n",
    "modulations_csv_filepath = f\"{root}/git/XLRON/examples/modulations.csv\"\n",
    "def check_file(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        return False\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return sum(1 for _ in file) > 2\n",
    "    except IOError:\n",
    "        return False"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "92810f49607399af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T14:43:02.833986Z",
     "start_time": "2024-09-05T14:43:02.829009Z"
    }
   },
   "source": [
    "import jax\n",
    "jax.devices()"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T14:42:52.479370Z",
     "start_time": "2024-09-05T14:42:37.451844Z"
    }
   },
   "source": [
    "env_type = \"rmsa\"\n",
    "topologies = [\"nsfnet_deeprmsa\", \"cost239_deeprmsa\"]\n",
    "heuristics = ['ksp_ff', 'ff_ksp', \"ksp_bf\", \"bf_ksp\", \"kme_ff\", \"kmc_ff\", \"kmf_ff\", \"kca_ff\"]\n",
    "k_range = range(1, 11)\n",
    "load_range = [50, 100, 150, 200, 250, 300, 400, 500, 600, 800]\n",
    "# Choice of traffic load - should be sufficient to cover wide range of blocking probs from <1% to 10%\n",
    "\n",
    "commands = []\n",
    "for topology in topologies:\n",
    "    for heuristic in heuristics:\n",
    "        for k in k_range:\n",
    "            for load in load_range:\n",
    "                output_file = f\"{data_directory}/kpaths/{env_type}/{topology}/{heuristic}_k{k}_{load}.csv\"\n",
    "                if check_file(output_file):\n",
    "                    print(f'Skipping file {output_file}')\n",
    "                    pass\n",
    "                else:\n",
    "                    commands.append(f\"python3 {script_path} --VISIBLE_DEVICES=3 --link_resources=100 --max_requests=1000 --max_timesteps=1000 --TOTAL_TIMESTEPS 10000 --NUM_ENVS 1 --NUM_SEEDS 100 --mean_service_holding_time=25 --ENV_WARMUP_STEPS 5000 --continuous_operation --noPLOTTING --ACTION_MASKING --EVAL_HEURISTIC --k {k} --env_type={env_type} --topology_name={topology} --path_heuristic {heuristic} --DATA_OUTPUT_FILE {output_file} --load={load} --modulations_csv_filepath {modulations_csv_filepath}\")\n",
    "\n",
    "print(f\"Total commands to run: {len(commands)}\")\n",
    "# Loop through the commands and run each one\n",
    "for i, cmd in enumerate(commands):\n",
    "    print(f\"Commands left: {len(commands) - i}\")\n",
    "    print(f\"Running command {i+1}: {cmd}\")\n",
    "    !{cmd}"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "b43f4fd386af69f9",
   "metadata": {},
   "source": [
    "env_type = \"rwa_lightpath_reuse\"\n",
    "num_seeds = 100\n",
    "topologies = [\"cost239\", \"nsfnet\"]\n",
    "heuristics = ['ksp_ff', 'ff_ksp', 'ksp_mu']#, 'ksp_mu_nonrel', 'ksp_mu_unique', 'mu_ksp', 'mu_ksp_nonrel', 'mu_ksp_unique']\n",
    "num_requests_nsfnet = [1e4, 1e4, 1.5e4, 2e4, 2.5e4]\n",
    "num_requests_cost239 = [2e4, 2e4, 2.5e4, 3e4, 3.5e4]\n",
    "k_range = range(1, 11)\n",
    "\n",
    "commands = []\n",
    "for topology in topologies:\n",
    "    num_requests_list = num_requests_nsfnet if topology==\"nsfnet\" else num_requests_cost239\n",
    "    for heuristic in heuristics:\n",
    "        for i, num_requests in enumerate(num_requests_list):\n",
    "            first_blocking = (i == 0)\n",
    "            for k in range(1, 11):\n",
    "                output_file = f\"{data_directory}/kpaths/{env_type}/{topology}/{heuristic}_k{k}_{num_requests:.0f}{'_firstblocking' if first_blocking else ''}.csv\"\n",
    "                if check_file(output_file):\n",
    "                    print(f'Skipping file {output_file}')\n",
    "                    pass\n",
    "                commands.append(f\"python3 ../xlron/train/train.py --VISIBLE_DEVICES=3 --k {k} --env_type={env_type} --topology_name={topology} --link_resources=100 --max_requests={num_requests} --max_timesteps={num_requests} --values_bw=100 --TOTAL_TIMESTEPS {int(num_requests)} --NUM_ENVS 1 --NUM_SEEDS {num_seeds} --ACTION_MASKING --incremental_loading {'--end_first_blocking' if first_blocking else ''} --EVAL_HEURISTIC --path_heuristic {heuristic} --DATA_OUTPUT_FILE {output_file}\")\n",
    "\n",
    "print(f\"Total commands to run: {len(commands)}\")\n",
    "# Loop through the commands and run each one\n",
    "for i, cmd in enumerate(commands):\n",
    "    print(f\"Commands left: {len(commands) - i}\")\n",
    "    print(f\"Running command {i+1}: {cmd}\")\n",
    "    !{cmd}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "490a94e3296eec3a",
   "metadata": {},
   "source": [],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "787a35f5bcc57c80",
   "metadata": {},
   "source": [
    "# Read each of the generated files, get the mean accepted services (or metric of choice) and plot\n",
    "\n",
    "for end_first_blocking in [False, True]:\n",
    "    for topology in [\"cost239\", \"nsfnet\"]:\n",
    "        accepted_services = []\n",
    "        labels = []\n",
    "        for heuristic in [\n",
    "            'ksp_ff', \n",
    "            'ff_ksp', \n",
    "            #'ksp_mu', \n",
    "            #'mu_ksp', \n",
    "            \"ksp_mu_alt\", \n",
    "            \"mu_ksp_alt\"]:\n",
    "            mean_accepted_services = []\n",
    "            std_accepted_services = []\n",
    "            for k in range (1, 11):\n",
    "                output_file = f\"{data_directory}/kpaths/{env_type}/{topology}/{heuristic}{k}{'_firstblocking' if end_first_blocking else ''}.csv\"\n",
    "                df = pd.read_csv(output_file)\n",
    "                accepted_services.append(df['accepted_services'])\n",
    "                mean_accepted_services.append(df['accepted_services'].mean())\n",
    "                std_accepted_services.append(df['accepted_services'].std())\n",
    "                print(f\"Mean accepted services for {heuristic}{k}: {df['accepted_services'].mean()}\")\n",
    "                labels.append(f\"{heuristic}{k}\")\n",
    "            plt.plot(range(1, 11), mean_accepted_services, label=heuristic)\n",
    "            plt.fill_between(range(1, 11), np.array(mean_accepted_services) - np.array(std_accepted_services), np.array(mean_accepted_services) + np.array(std_accepted_services), alpha=0.2)\n",
    "        plt.xlabel(\"k\")\n",
    "        plt.xticks(range(1, 11))\n",
    "        plt.ylabel(\"Mean accepted services\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.title(f\"{topology}-{'first blocking' if end_first_blocking else 'fixed length'}\")\n",
    "        plt.show()\n",
    "        # Plot as a boxplot\n",
    "        # plt.boxplot(accepted_services, labels=labels)\n",
    "        # plt.xlabel(\"k\")\n",
    "        # plt.ylabel(\"Mean accepted services\")\n",
    "        # plt.legend()\n",
    "        # plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "7648918a4f672588",
   "metadata": {},
   "source": [
    "# Same but for first blocking\n",
    "commands = []\n",
    "for topology in [\"cost239\", \"nsfnet\"]:\n",
    "    for num_requests in [1e4, 2e4, 3e4, 4e4]:\n",
    "        for heuristic in ['ksp_ff', 'ff_ksp', 'ksp_mu', 'mu_ksp', \"ksp_mu_alt\", \"mu_ksp_alt\"]:\n",
    "            for k in range(1, 11):\n",
    "                output_file = f\"{data_directory}/kpaths/{env_type}/{topology}/{heuristic}{k}{str(int(num_requests))}.csv\"\n",
    "                commands.append(f\"python3 ../xlron/train/train.py --k {k} --env_type={env_type} --topology_name={topology} --link_resources=100 --max_requests={num_requests} --max_timesteps={num_requests} --values_bw=100 --TOTAL_TIMESTEPS 120000 --NUM_ENVS 1 --NUM_SEEDS 1 --ACTION_MASKING --incremental_loading  --EVAL_HEURISTIC --path_heuristic {heuristic} --DATA_OUTPUT_FILE {output_file}\")\n",
    "            \n",
    "# Loop through the commands and run each one\n",
    "for i, cmd in enumerate(commands):\n",
    "    print(f\"Running command {i+1}: {cmd}\")\n",
    "    !{cmd}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a2d88a0f07ef4b12",
   "metadata": {},
   "source": [
    "\n",
    "for topology in [\"cost239\", \"nsfnet\"]:\n",
    "    for num_requests in [1e4, 2e4, 3e4, 4e4]:\n",
    "        accepted_services = []\n",
    "        labels = []\n",
    "        for heuristic in [\n",
    "            'ksp_ff', \n",
    "            'ff_ksp', \n",
    "            'ksp_mu', \n",
    "            'mu_ksp', \n",
    "            \"ksp_mu_alt\", \n",
    "            \"mu_ksp_alt\"]:\n",
    "            mean_accepted_services = []\n",
    "            std_accepted_services = []\n",
    "            for k in range (1, 11):\n",
    "                output_file = f\"{data_directory}/kpaths/{env_type}/{topology}/{heuristic}{k}{str(int(num_requests))}.csv\"\n",
    "                df = pd.read_csv(output_file)\n",
    "                accepted_services.append(df['accepted_services'])\n",
    "                mean_accepted_services.append(df['accepted_services'].mean())\n",
    "                std_accepted_services.append(df['accepted_services'].std())\n",
    "                print(f\"Mean accepted services for {heuristic}{k}: {df['accepted_services'].mean()}\")\n",
    "                labels.append(f\"{heuristic}{k}\")\n",
    "            plt.plot(range(1, 11), mean_accepted_services, label=heuristic)\n",
    "            plt.fill_between(range(1, 11), np.array(mean_accepted_services) - np.array(std_accepted_services), np.array(mean_accepted_services) + np.array(std_accepted_services), alpha=0.2)\n",
    "        plt.xlabel(\"k\")\n",
    "        plt.xticks(range(1, 11))\n",
    "        plt.ylabel(\"Mean accepted services\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.title(f\"{topology}-{num_requests}\")\n",
    "        plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "e6096fd206138371",
   "metadata": {},
   "source": [
    "# Same but for dynamic RMSA environment\n",
    "env_type = \"rmsa\"\n",
    "commands = []\n",
    "for topology in [\"nsfnet_deeprmsa\"]:\n",
    "    for weight in [True, False]:\n",
    "        for heuristic in ['ksp_ff', 'ff_ksp', 'kmf_ff', 'kmc_ff']:#, 'ksp_mu', 'mu_ksp']:\n",
    "            for k in range(1, 11):\n",
    "                output_file = f\"{data_directory}/kpaths/{env_type}/{topology}/{heuristic}{k}{'_weighted' if weight else ''}_deeprmsa.csv\"\n",
    "                commands.append(f\"python3 ../xlron/train/train.py --k {k} --env_type={env_type} --topology_name={topology} --link_resources=100 --max_requests=1e3 --max_timesteps=1e3 --load=250 --mean_service_holding_time=25 --TOTAL_TIMESTEPS 120000 --NUM_ENVS 1 --NUM_SEEDS 1 --ACTION_MASKING  --EVAL_HEURISTIC --path_heuristic {heuristic} --DATA_OUTPUT_FILE {output_file} --truncate_holding_time --ENV_WARMUP_STEPS 3000 --continuous_operation {'--weight weight' if weight else ''}\")\n",
    "# Loop through the commands and run each one\n",
    "for i, cmd in enumerate(commands):\n",
    "    print(f\"Running command {i+1}: {cmd}\")\n",
    "    !{cmd}"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "a590b7a5af8c6bed",
   "metadata": {},
   "source": [
    "env_type = \"rmsa\"\n",
    "commands = []\n",
    "for metric in [\"service_blocking_probability\", \"bitrate_blocking_probability\"]:\n",
    "    for topology in [\"nsfnet_deeprmsa\"]:\n",
    "        for weight in [True, False]:\n",
    "            accepted_services = []\n",
    "            labels = []\n",
    "            for heuristic in ['ksp_ff', 'ff_ksp', 'kmc_ff']:#, \"kmf_ff\"]:#, 'mu_ksp', 'ksp_mu']: \n",
    "                mean_accepted_services = []\n",
    "                std_accepted_services = []\n",
    "                for k in range (1, 11):\n",
    "                    output_file = f\"{data_directory}/kpaths/{env_type}/{topology}/{heuristic}{k}{'_weighted' if weight else ''}_deeprmsa.csv\"\n",
    "                    df = pd.read_csv(output_file)\n",
    "                    accepted_services.append(df[metric])\n",
    "                    mean_accepted_services.append(df[metric].mean())\n",
    "                    std_accepted_services.append(df[metric].std())\n",
    "                    print(f\"Mean {metric} for {heuristic}{k}: {df[metric].mean()}\")\n",
    "                    labels.append(f\"{heuristic}{k}\")\n",
    "                plt.plot(range(1, 11), mean_accepted_services, label=heuristic)\n",
    "                plt.fill_between(range(1, 11), np.array(mean_accepted_services) - np.array(std_accepted_services), np.array(mean_accepted_services) + np.array(std_accepted_services), alpha=0.2)\n",
    "        plt.xlabel(\"k\")\n",
    "        plt.xticks(range(1, 11))\n",
    "        plt.ylabel(f\"Mean {metric}\")\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "        plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "cc870c06a7e38d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T15:12:00.283142Z",
     "start_time": "2024-09-05T15:11:57.522832Z"
    }
   },
   "source": [
    "# To find the effect of truncating the holding time ot be less than 2*mean\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Set up Helvetica font\n",
    "mpl.rcParams['font.family'] = 'sans-serif'\n",
    "mpl.rcParams['font.sans-serif'] = ['Helvetica', 'Arial', 'DejaVu Sans', 'Bitstream Vera Sans', 'sans-serif']\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "def deeprmsa_sample(mean):\n",
    "    holding_time = np.random.exponential(mean)\n",
    "    while holding_time > 2*mean:\n",
    "        holding_time = np.random.exponential(mean)\n",
    "    return holding_time\n",
    "\n",
    "# plot the distribution of holding times\n",
    "mean = 25\n",
    "n_samples = 1000000\n",
    "deeprmsa = np.array([deeprmsa_sample(mean) for i in range(n_samples)])\n",
    "rmsa = np.array([np.random.exponential(mean) for i in range(n_samples)])\n",
    "max_ht = mean#max(max(deeprmsa), max(rmsa))\n",
    "deeprmsa_norm = deeprmsa/max_ht\n",
    "rmsa_norm = rmsa/max_ht\n",
    "mean_ht_truncated = np.mean(deeprmsa_norm)\n",
    "mean_ht = np.mean(rmsa_norm)\n",
    "bins = np.arange(0, 10.01, 0.01)\n",
    "weights = np.ones_like(rmsa_norm) / len(rmsa_norm)\n",
    "plt.hist(deeprmsa_norm, bins=bins, label=\"Truncated\", alpha=0.5, density=True)\n",
    "plt.hist(rmsa_norm, bins=bins, label=\"Not truncated\", alpha=0.5, density=True)\n",
    "plt.axvline(mean_ht_truncated, color='b', linestyle='dashed', linewidth=1, label=\"Mean truncated\")\n",
    "plt.axvline(mean_ht, color='r', linestyle='dashed', linewidth=1, label=\"Mean not truncated\")\n",
    "# Legend with 12 text size\n",
    "plt.legend(fontsize=11)\n",
    "plt.xlabel(\"Normalised holding time\", size=14)\n",
    "plt.ylabel(\"Density\", size=14)\n",
    "plt.xlim([0,6])\n",
    "# Make x and y ticks larger\n",
    "plt.xticks(size=12)\n",
    "plt.yticks(size=12)\n",
    "# Add a box saying the ratio of the means\n",
    "# Draw an arrow pointing from mean_ht to mean_ht_truncated\n",
    "plt.arrow(mean_ht, 0.8, -mean_ht+mean_ht_truncated, 0, head_width=0.05, head_length=0.1, fc='k', ec='k', length_includes_head=True)\n",
    "plt.text(mean_ht+0.15, 0.75, f\"{int(((mean_ht-mean_ht_truncated) / mean_ht)*100)}% decrease in\\nmean holding time\", bbox=dict(facecolor='white', alpha=0.5), size=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"truncation.png\")\n",
    "plt.show()\n"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "6971d2dde6e15b45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T14:44:01.147302Z",
     "start_time": "2024-09-05T14:43:31.796244Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "ratios = []\n",
    "for mean_holding_time in [5,10,15,20,25,30]:\n",
    "    hts = []\n",
    "    for i in range(10000000):\n",
    "        holding_time = deeprmsa_sample(mean_holding_time)\n",
    "        hts.append(holding_time)\n",
    "    real_mean_ht = np.mean(hts)\n",
    "    ratio = real_mean_ht/mean_holding_time\n",
    "    ratios.append(ratio)\n",
    "    print(f\"Real mean: {real_mean_ht}\")\n",
    "    print(f\"Ration of real to expected: {real_mean_ht/mean_holding_time}\")\n",
    "real_mean = np.mean(ratios)\n",
    "real_std = np.sqrt(np.sum(((np.array(ratios)-real_mean)**2)/(len(ratios)-1)))\n",
    "print(real_mean)\n",
    "print(real_std)"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5168b1e4a4f0fed8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T15:43:28.566404Z",
     "start_time": "2024-09-05T15:12:42.381262Z"
    }
   },
   "source": [
    "# Investigate steady state condition\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "mean_service_holding_time = 25\n",
    "arrival_rate = 10\n",
    "load = mean_service_holding_time*arrival_rate\n",
    "num_requests = 100000\n",
    "active_services = []\n",
    "current_time = 0\n",
    "\n",
    "results = []\n",
    "for repeats in range(1000):\n",
    "    for load in np.arange(50,1050,50):\n",
    "        for arrival_rate in [5, 10, 15, 20, 25]:\n",
    "            mean_service_holding_time = load/arrival_rate\n",
    "        #for mean_service_holding_time in [5, 10, 15, 20, 25, 30]:\n",
    "        #    load = mean_service_holding_time*arrival_rate\n",
    "            active_services = []\n",
    "            current_time = 0\n",
    "            for i in range(num_requests):\n",
    "                current_time += np.random.exponential(1/arrival_rate)\n",
    "                holding_time = np.random.exponential(mean_service_holding_time)\n",
    "                active_services.append(current_time + holding_time)\n",
    "                active_services = [x for x in active_services if x > current_time]\n",
    "                if len(active_services) >= load:\n",
    "                    data = {\"arrival_rate\": arrival_rate, \"mean_service_holding_time\": mean_service_holding_time, \"load\": load, \"current_time\": current_time, \"active_services\": len(active_services), \"num_requests\": i}\n",
    "                    results.append(data)\n",
    "                    break\n",
    "df = pd.DataFrame(results)\n",
    "# df_mean = df.groupby([\"arrival_rate\", \"mean_service_holding_time\"]).mean()\n",
    "# df_mean = df_mean.reset_index()\n",
    "# df_std = df.groupby([\"arrival_rate\", \"mean_service_holding_time\"]).std()\n",
    "# df_std = df_std.reset_index()\n",
    "# df = df_mean.merge(df_std, on=[\"arrival_rate\", \"mean_service_holding_time\"], suffixes=('_mean', '_std'))\n",
    "df"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "28209a9c15457c96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T15:43:28.590138Z",
     "start_time": "2024-09-05T15:43:28.569259Z"
    }
   },
   "source": [
    "# Plot the mean steady state requests against load and fit a line\n",
    "df_mean = df.groupby(\"load\").mean()\n",
    "df_mean = df_mean.reset_index()\n",
    "df_std = df.groupby(\"load\").std()\n",
    "df_std = df_std.reset_index()\n",
    "df_mean = df_mean.merge(df_std, on=\"load\", suffixes=('_mean', '_std'))\n"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "2465cd95d8ead8ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T15:43:28.843706Z",
     "start_time": "2024-09-05T15:43:28.590855Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 6))\n",
    "\n",
    "# Get series of num_requests for each load\n",
    "requests = [df[df[\"load\"] == load][\"num_requests\"] for load in sorted(df[\"load\"].unique())]\n",
    "loads = sorted(df[\"load\"].unique())\n",
    "\n",
    "# Create box plot\n",
    "bp = ax.boxplot(requests, positions=loads, widths=20, patch_artist=True, showfliers=False, showmeans=True)\n",
    "\n",
    "# Customize box appearance\n",
    "for box in bp['boxes']:\n",
    "    box.set(facecolor='white', edgecolor='black')\n",
    "for whisker in bp['whiskers']:\n",
    "    whisker.set(color='black')\n",
    "for cap in bp['caps']:\n",
    "    cap.set(color='black')\n",
    "for median in bp['medians']:\n",
    "    median.set(color='red')\n",
    "\n",
    "# Extract upper whisker values\n",
    "upper_whiskers = [item.get_ydata()[1] for item in bp['whiskers'][1::2]]\n",
    "\n",
    "# Fit a line to the upper whiskers\n",
    "coeffs = np.polyfit(loads, upper_whiskers, 1)\n",
    "print(coeffs)\n",
    "poly = np.poly1d(coeffs)\n",
    "\n",
    "# Calculate R-squared\n",
    "y_pred = poly(loads)\n",
    "y_mean = np.mean(upper_whiskers)\n",
    "ss_tot = np.sum((upper_whiskers - y_mean)**2)\n",
    "ss_res = np.sum((upper_whiskers - y_pred)**2)\n",
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "# Plot the fitted line with R-squared in the label\n",
    "ax.plot(loads, poly(loads), color='r', linestyle='--', \n",
    "        label=f'Fitted line: y = {coeffs[0]:.2f}x {\"+\" if coeffs[1]>0 else \"-\"} {abs(coeffs[1]):.0f}\\nR² = {r_squared:.4f}')\n",
    "\n",
    "ax.set_xlabel(\"Traffic load\", size=18)\n",
    "ax.set_ylabel(\"Requests until steady state\", size=18)\n",
    "ax.legend(fontsize=16)\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "\n",
    "# Set x-axis ticks to show load/100\n",
    "ax.set_xticks(loads[1::2])  # Show every other tick to avoid crowding\n",
    "ax.set_xticklabels([f'{load:.0f}' for load in loads[1::2]])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"steady_state_boxplots.png\")\n",
    "plt.show()"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e133d4942b042bd1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:47:41.011096Z",
     "start_time": "2024-07-08T16:45:11.978269Z"
    }
   },
   "source": [
    "# Investigate the effect of truncating the holding time on traffic load\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "def deeprmsa_sample(mean):\n",
    "    holding_time = np.random.exponential(mean)\n",
    "    while holding_time > 2*mean:\n",
    "        holding_time = np.random.exponential(mean)\n",
    "    return holding_time\n",
    "\n",
    "num_requests = 10000\n",
    "results = []\n",
    "\n",
    "for repeats in range(10):\n",
    "    for load in np.arange(50,1050,50):\n",
    "        for arrival_rate in [5, 10, 15, 20, 25]:\n",
    "            mean_service_holding_time = load/arrival_rate\n",
    "            active_services = []\n",
    "            current_time = 0\n",
    "            for i in range(load*7):\n",
    "                current_time += np.random.exponential(1/arrival_rate)\n",
    "                holding_time = deeprmsa_sample(mean_service_holding_time)\n",
    "                active_services.append(current_time + holding_time)\n",
    "                active_services = [x for x in active_services if x > current_time]\n",
    "            for i in range(num_requests):\n",
    "                current_time += np.random.exponential(1/arrival_rate)\n",
    "                holding_time = deeprmsa_sample(mean_service_holding_time)\n",
    "                active_services.append(current_time + holding_time)\n",
    "                active_services = [x for x in active_services if x > current_time]\n",
    "                data = {\"arrival_rate\": arrival_rate, \"mean_service_holding_time\": mean_service_holding_time, \"load\": load, \"current_time\": current_time, \"active_services\": len(active_services), \"num_requests\": i}\n",
    "                results.append(data)\n",
    "df = pd.DataFrame(results)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "389e761e595f0afb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-08T16:51:52.897749Z",
     "start_time": "2024-07-08T16:51:51.653581Z"
    }
   },
   "source": [
    "# For each load and arrivla rate, plot active services vs i\n",
    "# Plot the mean steady state requests against load and fit a line\n",
    "df_mean = df.groupby([\"load\", \"arrival_rate\"]).mean()\n",
    "df_mean = df_mean.reset_index()\n",
    "df_std = df.groupby([\"load\", \"arrival_rate\"]).std()\n",
    "df_std = df_std.reset_index()\n",
    "df_grouped = df_mean.merge(df_std, on=[\"load\", \"arrival_rate\"], suffixes=('_mean', '_std'))\n",
    "df_grouped = df_grouped.reset_index()\n",
    "df_grouped"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7758feb53ff3b301",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Set up Helvetica font\n",
    "mpl.rcParams['font.family'] = 'sans-serif'\n",
    "mpl.rcParams['font.sans-serif'] = ['Helvetica', 'Arial', 'DejaVu Sans', 'Bitstream Vera Sans', 'sans-serif']\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "# Assuming df_grouped is already created as in your code\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create scatter plot with error bars\n",
    "for arrival_rate in df_grouped['arrival_rate'].unique():\n",
    "    data = df_grouped[df_grouped['arrival_rate'] == arrival_rate]\n",
    "    ax.errorbar(data['load'], data['active_services_mean'], \n",
    "                yerr=data['active_services_std'], \n",
    "                fmt='o', capsize=5, label=f'Arrival Rate: {arrival_rate}')\n",
    "\n",
    "# Fit a line to all data points\n",
    "x = df_grouped['load']\n",
    "y = df_grouped['active_services_mean']\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "# Plot the fitted line\n",
    "line = slope * x + intercept\n",
    "ax.plot(x, line, color='r', linestyle='--', \n",
    "        label=f'Fitted line: y = {slope:.2f}x {\"+\" if intercept>0 else \"-\"} {abs(intercept):.0f}\\nR² = {r_value**2:.4f}')\n",
    "\n",
    "ax.set_xlabel(\"Expected traffic load [Erlang]\", size=18)\n",
    "ax.set_ylabel(\"Active Services\", size=18)\n",
    "ax.legend(fontsize=16)\n",
    "plt.xticks(size=16)\n",
    "plt.yticks(size=16)\n",
    "\n",
    "# Set x-axis ticks to show load/100\n",
    "ax.set_xticks(np.arange(100,1100,100))  # Show every other tick to avoid crowding\n",
    "\n",
    "# Add a box underneath the line saying actual traffic 69% of expected\n",
    "# Draw an arrow pointing from the line to the box\n",
    "plt.arrow(680, 310, 0, 600*0.25, head_width=10, head_length=10, fc='k', ec='k', length_includes_head=True)\n",
    "plt.text(580, 280, \"Actual traffic 69% of expected\", bbox=dict(facecolor='white', alpha=0.5), size=16)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"accepted_services_vs_load.png\")\n",
    "plt.show()\n",
    "\n",
    "# Print additional statistics\n",
    "print(f\"Slope: {slope:.4f}\")\n",
    "print(f\"Intercept: {intercept:.4f}\")\n",
    "print(f\"R-squared: {r_value**2:.4f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "print(f\"Standard Error: {std_err:.4f}\")"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
