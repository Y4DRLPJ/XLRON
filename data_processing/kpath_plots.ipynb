{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "202fe4a76785f9ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T00:53:13.241776Z",
     "start_time": "2024-06-30T00:53:13.225145Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Run the train script for each value of k\n",
    "root = \"/Users/michaeldoherty\"  # /home/uceedoh\n",
    "data_directory = f\"{root}/git/XLRON/data/JOCN_SI/heuristic_benchmarks\"\n",
    "script_path = f\"{root}/git/XLRON/xlron/train/train.py\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T00:53:13.269664Z",
     "start_time": "2024-06-30T00:53:13.263247Z"
    }
   },
   "source": [
    "def read_rmsa_files(topology, heuristic, k, load, weighted=False):\n",
    "    # Choice of traffic load - should be sufficient to cover wide range of blocking probs from <1% to 10%\n",
    "    weight = \"_weighted\" if weighted else \"\"\n",
    "    output_file = f\"{data_directory}/kpaths/rmsa/{topology}/{heuristic}{weight}_k{k}_{load}.csv\"\n",
    "    df = pd.read_csv(output_file)\n",
    "    return df\n",
    "\n",
    "\n",
    "def read_rwa_lightpath_reuse_files(topology, heuristic, k, num_requests, first_blocking=False, weighted=False):\n",
    "    weight = \"_weighted\" if weighted else \"\"\n",
    "    output_file = f\"{data_directory}/kpaths/rwa_lightpath_reuse/{topology}/{heuristic}{weight}_k{k}_{num_requests:.0f}{'_firstblocking' if first_blocking else ''}.csv\"\n",
    "    df = pd.read_csv(output_file)\n",
    "    return df\n",
    "             "
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad582041b5e0072e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T00:43:35.808480Z",
     "start_time": "2024-06-30T00:43:35.806007Z"
    }
   },
   "source": [
    "# Data values for reference\n",
    "env_type = \"rmsa\"\n",
    "topologies = [\"nsfnet_deeprmsa\", \"cost239_deeprmsa\"]\n",
    "heuristics = ['ksp_ff', 'ff_ksp', \"ksp_bf\", \"bf_ksp\", \"kme_ff\", \"kmc_ff\", \"kmf_ff\", \"kca_ff\"]\n",
    "k_range = range(1, 11)\n",
    "load_range = [50, 100, 150, 200, 250, 300, 400, 500, 600, 800]\n",
    "# Choice of traffic load - should be sufficient to cover wide range of blocking probs from <1% to 10%\n",
    "\n",
    "env_type = \"rwa_lightpath_reuse\"\n",
    "topologies = [\"cost239\", \"nsfnet\"]\n",
    "heuristics = ['ksp_ff', 'ff_ksp', 'ksp_mu']#, 'ksp_mu_nonrel', 'ksp_mu_unique', 'mu_ksp', 'mu_ksp_nonrel', 'mu_ksp_unique']\n",
    "num_requests_nsfnet = [1e4, 1e4, 1.5e4, 2e4, 2.5e4]\n",
    "num_requests_cost239 = [2e4, 2e4, 2.5e4, 3e4, 3.5e4]\n",
    "k_range = range(1, 11)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c253d15c961b2b8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T00:43:37.418135Z",
     "start_time": "2024-06-30T00:43:36.378668Z"
    },
    "scrolled": true
   },
   "source": [
    "topologies = [\"nsfnet_deeprmsa\", \"cost239_deeprmsa\"]\n",
    "heuristics = ['ksp_ff', 'ff_ksp', \"ksp_bf\", \"bf_ksp\", \"kme_ff\", \"kmc_ff\", \"kmf_ff\", \"kca_ff\"]\n",
    "k_range = range(1, 11)\n",
    "load_range = [50, 100, 150, 200, 250, 300, 400, 500, 600, 800]\n",
    "tables = []\n",
    "for topology in topologies:\n",
    "    rows = []\n",
    "    for heuristic in heuristics:\n",
    "        row = []\n",
    "        for k in k_range:\n",
    "            for load in load_range:\n",
    "                df = read_rmsa_files(topology, heuristic, k, load)\n",
    "                service_blocking_probability_mean = df[\"service_blocking_probability\"].mean()\n",
    "                # Get mean variance and take sqrt\n",
    "                service_blocking_probability_std = np.sqrt(np.sum(df[\"service_blocking_probability_std\"]**2)/len(df))\n",
    "                row.append(service_blocking_probability_mean)\n",
    "                row.append(service_blocking_probability_std)\n",
    "        rows.append(row)\n",
    "    table = pd.DataFrame(rows, columns=pd.MultiIndex.from_product([k_range, load_range, [\"mean\", \"std\"]], names=['k', 'load', 'BP']), index=pd.Index(heuristics, name='Heuristic'))\n",
    "    tables.append(table)\n",
    "\n",
    "# Best heuristic for each load\n",
    "for i, table in enumerate(tables):\n",
    "    topology = topologies[i]\n",
    "    best_heuristics_all_loads = []\n",
    "    for load in load_range:\n",
    "        result_mean = table.loc[:, (slice(None), load, 'mean')].droplevel(['load', 'BP'], axis=1)\n",
    "        result_std = table.loc[:, (slice(None), load, 'std')].droplevel(['load', 'BP'], axis=1)\n",
    "        \n",
    "        # Find the minimum mean value\n",
    "        min_value = result_mean.min().min()\n",
    "        \n",
    "        # Find the index (heuristic) and column (k) of the minimum mean value\n",
    "        min_index, min_column = result_mean.stack().idxmin()\n",
    "        \n",
    "        # Get the corresponding std value\n",
    "        std_value = result_std.loc[min_index, min_column]\n",
    "        \n",
    "        print(f\"Load: {load}\")\n",
    "        print(f\"Minimum mean value: {min_value:.6f}\")\n",
    "        print(f\"Corresponding std value: {std_value:.6f}\")\n",
    "        print(f\"Heuristic: {min_index}\")\n",
    "        print(f\"k value: {min_column}\")\n",
    "        \n",
    "        # Find similar performing configurations\n",
    "        lower_bound = min_value - std_value\n",
    "        upper_bound = min_value + std_value\n",
    "        \n",
    "        similar_configs = result_mean[(result_mean >= lower_bound) & (result_mean <= upper_bound)]\n",
    "        similar_configs = similar_configs.stack().reset_index()\n",
    "        similar_configs.columns = ['Heuristic', 'k', 'BP_mean']\n",
    "        \n",
    "        # Get corresponding std values\n",
    "        similar_configs['BP_std'] = similar_configs.apply(lambda row: result_std.loc[row['Heuristic'], row['k']], axis=1)\n",
    "        \n",
    "        similar_configs = similar_configs.sort_values('BP_mean')\n",
    "        \n",
    "        print(\"\\nSimilar performing configurations:\")\n",
    "        best_hk = []\n",
    "        for _, row in similar_configs.iterrows():\n",
    "            hk = f\"{row['Heuristic']}-{row['k']}\"\n",
    "            best_hk.append(hk)\n",
    "            print(f\"Heuristic: {row['Heuristic']}, k: {row['k']}, BP mean: {row['BP_mean']:.6f} +/- {row['BP_std']:.6f}\")\n",
    "        print(\"Similar heuristics: \", similar_configs['Heuristic'].unique())\n",
    "        best_heuristics_all_loads.append(best_hk)\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "    for heuristic in heuristics:\n",
    "        for k in k_range:\n",
    "            hk = f\"{heuristic}-{k}\"\n",
    "            if all(hk in best_hk for best_hk in best_heuristics_all_loads):\n",
    "                print(f\"Best performing heuristic for all loads for {topology}: {hk}\")\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1887c9d6c613be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T01:05:51.406927Z",
     "start_time": "2024-06-30T01:05:51.277133Z"
    },
    "scrolled": true
   },
   "source": [
    "topologies = [\"nsfnet_deeprmsa\"]\n",
    "heuristics = ['ksp_ff']\n",
    "k_range = range(1, 11)\n",
    "load_range = [50, 100, 150, 200, 250, 300, 400, 500, 600, 800]\n",
    "tables = []\n",
    "for topology in topologies:\n",
    "    rows = []\n",
    "    for heuristic in heuristics:\n",
    "        for k in k_range:\n",
    "            row = []\n",
    "            for load in load_range:\n",
    "                df = read_rmsa_files(topology, heuristic, k, load, weighted=False)\n",
    "                service_blocking_probability_mean = df[\"service_blocking_probability\"].mean()\n",
    "                # Get mean variance and take sqrt\n",
    "                service_blocking_probability_std = np.sqrt(np.sum(df[\"service_blocking_probability_std\"]**2)/len(df))\n",
    "                row.append(service_blocking_probability_mean)\n",
    "                #row.append(service_blocking_probability_std)\n",
    "            rows.append(row)\n",
    "\n",
    "df_unweighted = pd.DataFrame(rows)\n",
    "        \n",
    "for topology in topologies:\n",
    "    rows = []\n",
    "    for heuristic in heuristics:\n",
    "        for k in k_range:\n",
    "            row = []\n",
    "            for load in load_range:\n",
    "                df = read_rmsa_files(topology, heuristic, k, load, weighted=True)\n",
    "                service_blocking_probability_mean = df[\"service_blocking_probability\"].mean()\n",
    "                # Get mean variance and take sqrt\n",
    "                service_blocking_probability_std = np.sqrt(np.sum(df[\"service_blocking_probability_std\"]**2)/len(df))\n",
    "                row.append(service_blocking_probability_mean)\n",
    "                #row.append(service_blocking_probability_std)\n",
    "            rows.append(row)\n",
    "               \n",
    "df_weighted = pd.DataFrame(rows)\n",
    "df_unweighted"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a54924613772aea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-30T01:10:04.986297Z",
     "start_time": "2024-06-30T01:10:04.972413Z"
    }
   },
   "source": [
    "# ((df_weighted - df_unweighted)/ df_unweighted)\n",
    "# column_names = [\"50\", \"100\", \"150\", \"200\", \"250\", \"300\", \"400\", \"500\", \"600\", \"800\"]\n",
    "# df_diff = ((df_weighted - df_unweighted)/ df_unweighted)\n",
    "# df_diff.columns = column_names\n",
    "# index = [\"k=1\", \"k=2\", \"k=3\", \"k=4\", \"k=5\", \"k=6\", \"k=7\", \"k=8\", \"k=9\", \"k=10\"]\n",
    "# df_diff.index = index\n",
    "# df_diff = df_diff.drop(columns=[\"50\"])\n",
    "# # Format values as percent\n",
    "# df_diff.style.format(\"{:.2%}\")\n",
    "# # Format color based on value. Use a color scale where green is for 0 and red is for anything over 0.1\n",
    "# df_diff.style.background_gradient(cmap='RdYlGn', axis=None).format(\"{:.0%}\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df_weighted and df_unweighted are already defined\n",
    "column_names = [\"50\", \"100\", \"150\", \"200\", \"250\", \"300\", \"400\", \"500\", \"600\", \"800\"]\n",
    "df_diff = ((df_weighted - df_unweighted) / df_unweighted)\n",
    "df_diff.columns = column_names\n",
    "index = [\"k=1\", \"k=2\", \"k=3\", \"k=4\", \"k=5\", \"k=6\", \"k=7\", \"k=8\", \"k=9\", \"k=10\"]\n",
    "df_diff.index = index\n",
    "df_diff = df_diff.drop(columns=[\"50\"])\n",
    "\n",
    "df_abs = (df_weighted - df_unweighted) \n",
    "df_abs.columns = column_names\n",
    "index = [\"k=1\", \"k=2\", \"k=3\", \"k=4\", \"k=5\", \"k=6\", \"k=7\", \"k=8\", \"k=9\", \"k=10\"]\n",
    "df_abs.index = index\n",
    "\n",
    "# Create a custom colormap\n",
    "def custom_cmap_diff(val):\n",
    "    if val < 0:\n",
    "        return f'background-color: rgba(0, 255, 0, {min(-val, 0.5)})'\n",
    "    else:\n",
    "        return f'background-color: rgba(255, 0, 0, {min(val, 0.5)})'\n",
    "\n",
    "# Create a custom colormap\n",
    "def custom_cmap_abs(val):\n",
    "    if val < 0:\n",
    "        return f'background-color: rgba(0, 255, 0, {min(-val, 0.5)})'\n",
    "    else:\n",
    "        return f'background-color: rgba(255, 0, 0, {min(val, 0.5)})'\n",
    "\n",
    "\n",
    "# Apply styling\n",
    "styled_df_diff = df_diff.style.applymap(custom_cmap_diff).format(\"{:.2%}\")\n",
    "styled_df_abs = df_abs.style.applymap(custom_cmap_diff).format(\"{:.2%}\")\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_df_diff\n",
    "styled_df_abs"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9681d5131b05b1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T20:19:22.433763Z",
     "start_time": "2024-06-29T20:19:22.431441Z"
    }
   },
   "source": [
    "# # Best k value for each load\n",
    "# for i, table in enumerate(tables):\n",
    "#     topology = topologies[i]\n",
    "#     best_k_all_loads = []\n",
    "#     for k in k_range:\n",
    "#         result_mean = table.loc[:, (slice(None), load, 'mean')].droplevel(['load', 'BP'], axis=1)\n",
    "#         result_std = table.loc[:, (slice(None), load, 'std')].droplevel(['load', 'BP'], axis=1)\n",
    "#         \n",
    "#         # Find the minimum mean value\n",
    "#         min_value = result_mean.min().min()\n",
    "#         \n",
    "#         # Find the index (heuristic) and column (k) of the minimum mean value\n",
    "#         min_index, min_column = result_mean.stack().idxmin()\n",
    "#         \n",
    "#         # Get the corresponding std value\n",
    "#         std_value = result_std.loc[min_index, min_column]\n",
    "#         \n",
    "#         print(f\"Load: {load}\")\n",
    "#         print(f\"Minimum mean value: {min_value:.6f}\")\n",
    "#         print(f\"Corresponding std value: {std_value:.6f}\")\n",
    "#         print(f\"Heuristic: {min_index}\")\n",
    "#         print(f\"k value: {min_column}\")\n",
    "#         \n",
    "#         # Find similar performing configurations\n",
    "#         lower_bound = min_value - std_value\n",
    "#         upper_bound = min_value + std_value\n",
    "#         \n",
    "#         similar_configs = result_mean[(result_mean >= lower_bound) & (result_mean <= upper_bound)]\n",
    "#         similar_configs = similar_configs.stack().reset_index()\n",
    "#         similar_configs.columns = ['Heuristic', 'k', 'BP_mean']\n",
    "#         \n",
    "#         # Get corresponding std values\n",
    "#         similar_configs['BP_std'] = similar_configs.apply(lambda row: result_std.loc[row['Heuristic'], row['k']], axis=1)\n",
    "#         \n",
    "#         similar_configs = similar_configs.sort_values('BP_mean')\n",
    "#         \n",
    "#         print(\"\\nSimilar performing configurations:\")\n",
    "#         for _, row in similar_configs.iterrows():\n",
    "#             print(f\"Heuristic: {row['Heuristic']}, k: {row['k']}, BP mean: {row['BP_mean']:.6f} +/- {row['BP_std']:.6f}\")\n",
    "#         print(\"Similar heuristics: \", similar_configs['Heuristic'].unique())\n",
    "#         best_heuristics_all_loads.append(similar_configs['Heuristic'].unique())\n",
    "#         \n",
    "#         print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "#     print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "#     for heuristic in heuristics:\n",
    "#         if all(heuristic in best_heuristics for best_heuristics in best_heuristics_all_loads):\n",
    "#             print(f\"Best performing heuristic for all loads for {topology}: {heuristic}\")\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f56b9e8485830bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T20:19:24.466721Z",
     "start_time": "2024-06-29T20:19:23.661343Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def format_heuristic(heuristic):\n",
    "    return heuristic.upper().replace('_', '-')\n",
    "\n",
    "topologies = [\"nsfnet_deeprmsa\", \"cost239_deeprmsa\"]\n",
    "heuristics = ['ksp_ff', 'ff_ksp', \"ksp_bf\", \"bf_ksp\", \"kme_ff\", \"kmc_ff\", \"kmf_ff\", \"kca_ff\"]\n",
    "k_range = range(1, 11)\n",
    "load_range = [50, 100, 150, 200, 250, 300, 400, 500, 600, 800]\n",
    "tables = []\n",
    "\n",
    "for topology in topologies:\n",
    "    data = []\n",
    "    for heuristic in heuristics:\n",
    "        for k in k_range:\n",
    "            row = []\n",
    "            for load in load_range:\n",
    "                df = read_rmsa_files(topology, heuristic, k, load)\n",
    "                service_blocking_probability_mean = df[\"service_blocking_probability\"].mean()\n",
    "                service_blocking_probability_std = np.sqrt(np.sum(df[\"service_blocking_probability_std\"]**2)/len(df))\n",
    "                row.extend([service_blocking_probability_mean, service_blocking_probability_std])\n",
    "            data.append([format_heuristic(heuristic), k] + row)\n",
    "    \n",
    "    # Create multi-index DataFrame with titled columns\n",
    "    columns = ['Heuristic', 'k']\n",
    "    for load in load_range:\n",
    "        columns.extend([(load, 'BP Mean'), (load, 'BP Std')])\n",
    "    \n",
    "    table = pd.DataFrame(data, columns=columns)\n",
    "    table = table.set_index(['Heuristic', 'k'])\n",
    "    \n",
    "    # Create a MultiIndex for the columns\n",
    "    table.columns = pd.MultiIndex.from_tuples(table.columns, names=['Load', 'Metric'])\n",
    "    \n",
    "    tables.append(table)\n",
    "\n",
    "# Example of how to display the table\n",
    "print(tables[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27b8d44c-5bf3-4f19-bfe4-bd70316c640b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T20:19:24.491933Z",
     "start_time": "2024-06-29T20:19:24.468012Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def keep_best_rows(table):\n",
    "    def row_mean(row):\n",
    "        return row.xs('BP Mean', level='Metric', axis=0).mean()\n",
    "    \n",
    "    best_indices = []\n",
    "    heuristics = table.index.get_level_values('Heuristic').unique()\n",
    "    \n",
    "    for heuristic in heuristics:\n",
    "        heuristic_rows = table.xs(heuristic, level='Heuristic')\n",
    "        best_row_index = heuristic_rows.apply(row_mean, axis=1).idxmin()\n",
    "        best_indices.append((heuristic, best_row_index))\n",
    "    \n",
    "    # Create a new index from the best indices\n",
    "    new_index = pd.MultiIndex.from_tuples(best_indices, names=['Heuristic', 'k'])\n",
    "    \n",
    "    # Use the new index to select the best rows from the original table\n",
    "    filtered_table = table.loc[new_index]\n",
    "    \n",
    "    return filtered_table\n",
    "\n",
    "\n",
    "keep_best_rows(tables[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "278871e3d88675e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T20:19:26.209094Z",
     "start_time": "2024-06-29T20:19:26.100208Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def format_table_for_publication_html(table):\n",
    "    \n",
    "    # Function to determine cell color\n",
    "    def color_cell(value, min_value, min_std):\n",
    "        if pd.isna(value):\n",
    "            return ''\n",
    "        if value <= min_value + min_std:\n",
    "            return 'background-color: green; color: white'\n",
    "        else:\n",
    "            return 'background-color: red; color: white'\n",
    "\n",
    "    #table = keep_best_rows(table)\n",
    "    \n",
    "    # Create a copy of the table with only BP Mean values\n",
    "    mean_table = table.xs('BP Mean', axis=1, level='Metric')\n",
    "    \n",
    "    # Find the minimum value and its corresponding std for each load\n",
    "    min_values = mean_table.min()\n",
    "    min_indices = mean_table.idxmin()\n",
    "    min_stds = pd.Series(index=min_values.index)\n",
    "    for load in min_values.index:\n",
    "        min_stds[load] = table.loc[min_indices[load], (load, 'BP Std')]\n",
    "    \n",
    "    # Apply coloring\n",
    "    styled_table = mean_table.style.apply(lambda col: [color_cell(v, min_values[col.name], min_stds[col.name]) for v in col], axis=0)\n",
    "    \n",
    "    # Format numbers\n",
    "    styled_table = styled_table.format(\"{:.4f}\")\n",
    "    \n",
    "    # Add a caption\n",
    "    #styled_table = styled_table.set_caption(\"Blocking Probability (BP) for different heuristics and loads. Green cells are within one standard deviation of the minimum BP for that load.\")\n",
    "    \n",
    "    return styled_table\n",
    "\n",
    "# Assuming 'tables' is your list of DataFrames, one for each topology\n",
    "for i, table in enumerate(tables):\n",
    "    styled_table = format_table_for_publication_html(table)\n",
    "    \n",
    "    # Display the table (in a Jupyter notebook this will show the formatted table)\n",
    "    display(styled_table)\n",
    "    \n",
    "    # Save to HTML (you can then copy this into your paper or convert to LaTeX)\n",
    "    styled_table.to_html(f'formatted_table_rmsa_{i}.html')\n",
    "\n",
    "# If you need LaTeX output, you can use a library like pandas_to_latex or manually convert the HTML\n",
    "\n",
    "# Plot the rows on a line chart of BP vs Load"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5bc7e8d6a0d4b97b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T20:19:27.532311Z",
     "start_time": "2024-06-29T20:19:27.527608Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.scale import ScaleBase, register_scale\n",
    "from matplotlib.transforms import Transform\n",
    "from matplotlib.ticker import AutoLocator, ScalarFormatter\n",
    "\n",
    "class LogLinearScale(ScaleBase):\n",
    "    name = 'loglinear'\n",
    "\n",
    "    def __init__(self, axis, **kwargs):\n",
    "        ScaleBase.__init__(self, axis)\n",
    "        self.thresh = kwargs.get('thresh', 0.1)\n",
    "\n",
    "    def get_transform(self):\n",
    "        return LogLinearTransform(self.thresh)\n",
    "\n",
    "    def set_default_locators_and_formatters(self, axis):\n",
    "        axis.set_major_locator(AutoLocator())\n",
    "        axis.set_major_formatter(ScalarFormatter())\n",
    "\n",
    "class LogLinearTransform(Transform):\n",
    "    input_dims = output_dims = 1\n",
    "\n",
    "    def __init__(self, thresh):\n",
    "        Transform.__init__(self)\n",
    "        self.thresh = thresh\n",
    "\n",
    "    def transform_non_affine(self, a):\n",
    "        mask = a < self.thresh\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            log_a = np.log10(a)\n",
    "        out = np.where(mask, log_a, a / self.thresh + np.log10(self.thresh) - 1)\n",
    "        return out\n",
    "\n",
    "    def inverted(self):\n",
    "        return InvertedLogLinearTransform(self.thresh)\n",
    "\n",
    "class InvertedLogLinearTransform(Transform):\n",
    "    input_dims = output_dims = 1\n",
    "\n",
    "    def __init__(self, thresh):\n",
    "        Transform.__init__(self)\n",
    "        self.thresh = thresh\n",
    "\n",
    "    def transform_non_affine(self, a):\n",
    "        return np.where(a < np.log10(self.thresh),\n",
    "                        10.0 ** a,\n",
    "                        (a - np.log10(self.thresh) + 1) * self.thresh)\n",
    "\n",
    "    def inverted(self):\n",
    "        return LogLinearTransform(self.thresh)\n",
    "\n",
    "# Register the custom scale\n",
    "register_scale(LogLinearScale)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "21d351a5-fcd5-4fde-987e-b22d6d397baf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T20:19:53.103024Z",
     "start_time": "2024-06-29T20:19:50.965415Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "convert_heuristic_name = lambda x: x[0].replace(\"K\", f\"{x[1]}-\")\n",
    "\n",
    "\n",
    "def plot_bp_vs_load(table, topology_name):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Extract BP Mean values\n",
    "    bp_mean = table.xs('BP Mean', axis=1, level='Metric')\n",
    "    bp_std = table.xs('BP Std', axis=1, level='Metric')\n",
    "    \n",
    "    # Get load values\n",
    "    loads = bp_mean.columns.astype(int)\n",
    "    \n",
    "    # Plot each heuristic\n",
    "    for heuristic in bp_mean.index:\n",
    "        plt.plot(loads, bp_mean.loc[heuristic], marker='o', label=convert_heuristic_name(heuristic))\n",
    "        # Plot std\n",
    "        plt.fill_between(loads, bp_mean.loc[heuristic] - bp_std.loc[heuristic], bp_mean.loc[heuristic] + bp_std.loc[heuristic], alpha=0.2)\n",
    "\n",
    "    # Get model eval data\n",
    "    if topology_name == \"NSFNET\":\n",
    "        model_eval = []\n",
    "        for load in load_range:\n",
    "            model_eval_file = f\"/Users/michaeldoherty/git/XLRON/data/JOCN_SI/deeprmsa_model_eval/JOCN_DEEPRMSA_MASKED_8_1_{load}.csv\"\n",
    "            df = pd.read_csv(model_eval_file)\n",
    "            mean_bp = df[\"service_blocking_probability\"].mean()\n",
    "            std_bp = np.sqrt(np.sum(df[\"service_blocking_probability_std\"] ** 2) / len(df))\n",
    "            model_eval.append([load, mean_bp, std_bp])\n",
    "        \n",
    "        model_eval_df = pd.DataFrame(model_eval, columns=['Load', 'BP Mean', 'BP Std'])\n",
    "        plt.plot(model_eval_df['Load'], model_eval_df['BP Mean'], label='XLRON', marker='o')\n",
    "        plt.fill_between(model_eval_df['Load'], model_eval_df['BP Mean'] - model_eval_df['BP Std'], model_eval_df['BP Mean'] + model_eval_df['BP Std'], alpha=0.2)\n",
    "    \n",
    "    plt.xlabel('Load (Erlangs)', fontsize=14)\n",
    "    plt.ylabel('Blocking pprobability', fontsize=14)\n",
    "    plt.xscale('linear')  # Use log scale for x-axis\n",
    "    plt.yscale('log')  # Use log scale for y-axis\n",
    "    plt.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "    plt.legend(fontsize=10, loc='upper left')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(f'bp_vs_load_{topology_name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Assuming 'tables' is your list of DataFrames, one for each topology\n",
    "topologies = [\"NSFNET\", \"COST239\"]  # Add your topology names here\n",
    "\n",
    "for i, table in enumerate(tables):\n",
    "    # Format and display the table\n",
    "    table = keep_best_rows(table)\n",
    "    styled_table = format_table_for_publication_html(table)\n",
    "    display(styled_table)\n",
    "    styled_table.to_html(f'formatted_table_rmsa_{i}.html')\n",
    "    \n",
    "    # Create the plot\n",
    "    table = table.replace(0, np.nan)\n",
    "    plot_bp_vs_load(table, topologies[i])\n",
    "\n",
    "print(\"Tables and plots have been saved.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "820e8ba302017018",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T21:26:49.048238Z",
     "start_time": "2024-06-29T21:26:45.538730Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def convert_heuristic_name(x):\n",
    "    return x[0].replace(\"K\", f\"{x[1]}-\")\n",
    "\n",
    "def plot_bp_vs_load(table, topology_name):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    \n",
    "    # Extract BP Mean values\n",
    "    bp_mean = table.xs('BP Mean', axis=1, level='Metric')\n",
    "    bp_std = table.xs('BP Std', axis=1, level='Metric')\n",
    "    \n",
    "    # Get load values\n",
    "    loads = bp_mean.columns.astype(int)\n",
    "\n",
    "    legend_lines = {}\n",
    "    # Plot each heuristic\n",
    "    for heuristic in bp_mean.index:\n",
    "        label = convert_heuristic_name(heuristic)\n",
    "        # First subplot (0-250, log scale)\n",
    "        mask1 = loads <= 250\n",
    "        line, = ax1.plot(loads[mask1], bp_mean.loc[heuristic, mask1], marker='o', label=label)\n",
    "        ax1.fill_between(loads[mask1], \n",
    "                         bp_mean.loc[heuristic, mask1] - bp_std.loc[heuristic, mask1], \n",
    "                         bp_mean.loc[heuristic, mask1] + bp_std.loc[heuristic, mask1], \n",
    "                         alpha=0.2)\n",
    "        legend_lines[label] = line\n",
    "        \n",
    "        \n",
    "        # Second subplot (250-800, linear scale)\n",
    "        mask2 = loads > 250\n",
    "        ax2.plot(loads[mask2], bp_mean.loc[heuristic, mask2], marker='o')\n",
    "        ax2.fill_between(loads[mask2], \n",
    "                         bp_mean.loc[heuristic, mask2] - bp_std.loc[heuristic, mask2], \n",
    "                         bp_mean.loc[heuristic, mask2] + bp_std.loc[heuristic, mask2], \n",
    "                         alpha=0.2)\n",
    "\n",
    "    # Get model eval data\n",
    "    if topology_name == \"NSFNET\":\n",
    "        model_eval = []\n",
    "        for load in loads:\n",
    "            model_eval_file = f\"/Users/michaeldoherty/git/XLRON/data/JOCN_SI/deeprmsa_model_eval/JOCN_DEEPRMSA_MASKED_8_1_{load}.csv\"\n",
    "            df = pd.read_csv(model_eval_file)\n",
    "            mean_bp = df[\"service_blocking_probability\"].mean()\n",
    "            std_bp = np.sqrt(np.sum(df[\"service_blocking_probability_std\"] ** 2) / len(df))\n",
    "            model_eval.append([load, mean_bp, std_bp])\n",
    "        \n",
    "        model_eval_df = pd.DataFrame(model_eval, columns=['Load', 'BP Mean', 'BP Std'])\n",
    "        \n",
    "        # First subplot\n",
    "        mask1 = model_eval_df['Load'] <= 250\n",
    "        line, = ax1.plot(model_eval_df.loc[mask1, 'Load'], model_eval_df.loc[mask1, 'BP Mean'], label='XLRON', marker='o')\n",
    "        ax1.fill_between(model_eval_df.loc[mask1, 'Load'], \n",
    "                         model_eval_df.loc[mask1, 'BP Mean'] - model_eval_df.loc[mask1, 'BP Std'], \n",
    "                         model_eval_df.loc[mask1, 'BP Mean'] + model_eval_df.loc[mask1, 'BP Std'], \n",
    "                         alpha=0.2)\n",
    "        legend_lines['XLRON']=line\n",
    "        \n",
    "        # Second subplot\n",
    "        mask2 = model_eval_df['Load'] > 250\n",
    "        ax2.plot(model_eval_df.loc[mask2, 'Load'], model_eval_df.loc[mask2, 'BP Mean'], marker='o')\n",
    "        ax2.fill_between(model_eval_df.loc[mask2, 'Load'], \n",
    "                         model_eval_df.loc[mask2, 'BP Mean'] - model_eval_df.loc[mask2, 'BP Std'], \n",
    "                         model_eval_df.loc[mask2, 'BP Mean'] + model_eval_df.loc[mask2, 'BP Std'], \n",
    "                         alpha=0.2)\n",
    "    \n",
    "    # Configure subplots\n",
    "    for ax in (ax1, ax2):\n",
    "        ax.set_xlabel('Load (Erlangs)', fontsize=20)\n",
    "        ax.grid(True, which=\"both\", ls=\"-\", alpha=0.2)\n",
    "        ax.tick_params(axis='both', which='major', labelsize=18)\n",
    "    \n",
    "    ax1.set_xlim(0, 250)\n",
    "    ax1.set_yscale('log')\n",
    "    ax2.set_xlim(250, 800)\n",
    "    ax1.set_ylim(1e-5, 0.2)\n",
    "    ax2.set_ylim(0, 0.5)\n",
    "    \n",
    "    # Set y-label only for the left subplot\n",
    "    ax1.set_ylabel('Blocking probability', fontsize=20)\n",
    "\n",
    "    # Add legend to the top left of the first subplot with custom order\n",
    "    legend_order = [\"BF-6-SP\", \"3-CA-FF\", \"3-MF-FF\", \"10-SP-BF\", \"FF-4-SP\", \"10-ME-FF\", \"9-SP-FF\", \"5-MC-FF\", \"XLRON\"]\n",
    "    ordered_legend = [legend_lines[label] for label in legend_order if label in legend_lines]\n",
    "    ax1.legend(ordered_legend, [\"BF-6-SP\", \"3-CA-FF\", \"3-MF-FF\", \"10-SP-BF\", \"FF-4-SP\", \"10-ME-FF\", \"9-SP-FF\", \"5-MC-FF\", \"XLRON\"], fontsize=16, loc='upper left')\n",
    "    \n",
    "    # Add legend to the top left of the first subplot\n",
    "    #ax1.legend(fontsize=16, loc='upper left')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the plot\n",
    "    plt.savefig(f'bp_vs_load_{topology_name}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# The rest of your code remains the same\n",
    "topologies = [\"NSFNET\", \"COST239\"]  # Add your topology names here\n",
    "\n",
    "for i, table in enumerate(tables):\n",
    "    # Format and display the table\n",
    "    table = keep_best_rows(table)\n",
    "    styled_table = format_table_for_publication_html(table)\n",
    "    display(styled_table)\n",
    "    styled_table.to_html(f'formatted_table_rmsa_{i}.html')\n",
    "    \n",
    "    # Create the plot\n",
    "    table = table.replace(0, np.nan)\n",
    "    plot_bp_vs_load(table, topologies[i])\n",
    "\n",
    "print(\"Tables and plots have been saved.\")\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6f3aebac404c03b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T11:25:51.620414Z",
     "start_time": "2024-06-29T11:25:39.791204Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def format_table_for_publication(table):\n",
    "    # Create a copy of the table with only BP Mean values\n",
    "    mean_table = table.xs('BP Mean', axis=1, level='Metric')\n",
    "    \n",
    "    # Find the minimum value and its corresponding std for each load\n",
    "    min_values = mean_table.min()\n",
    "    min_indices = mean_table.idxmin()\n",
    "    min_stds = pd.Series(index=min_values.index)\n",
    "    for load in min_values.index:\n",
    "        min_stds[load] = table.loc[min_indices[load], (load, 'BP Std')]\n",
    "    \n",
    "    return mean_table, min_values, min_stds\n",
    "\n",
    "def create_styled_table_png(table, min_values, min_stds, filename, dpi=300):\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(20, len(table) * 0.5))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Create the table\n",
    "    table_obj = ax.table(cellText=table.values,\n",
    "                         rowLabels=table.index,\n",
    "                         colLabels=table.columns,\n",
    "                         cellLoc='center',\n",
    "                         loc='center')\n",
    "    \n",
    "    # Style the table\n",
    "    table_obj.auto_set_font_size(False)\n",
    "    table_obj.set_fontsize(9)\n",
    "    table_obj.scale(1.2, 1.5)\n",
    "    \n",
    "    # Color the cells\n",
    "    for (row, col), cell in table_obj.get_celld().items():\n",
    "        if row == 0:  # Header\n",
    "            cell.set_facecolor('#4472C4')\n",
    "            cell.set_text_props(color='white')\n",
    "        elif col == -1:  # Row labels\n",
    "            cell.set_facecolor('#4472C4')\n",
    "            cell.set_text_props(color='white')\n",
    "        else:\n",
    "            value = table.iloc[row-1, col]\n",
    "            if value <= min_values[table.columns[col]] + min_stds[table.columns[col]]:\n",
    "                cell.set_facecolor('#C6EFCE')\n",
    "            else:\n",
    "                cell.set_facecolor('#FFC7CE')\n",
    "    \n",
    "    # Add title\n",
    "    plt.title('Blocking Probability (BP) for different heuristics and loads.\\n'\n",
    "              'Green cells are within one standard deviation of the minimum BP for that load.',\n",
    "              fontsize=12, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=dpi, bbox_inches='tight', pad_inches=0.5)\n",
    "    plt.close()\n",
    "\n",
    "# Assuming 'tables' is your list of DataFrames, one for each topology\n",
    "for i, table in enumerate(tables):\n",
    "    mean_table, min_values, min_stds = format_table_for_publication(table)\n",
    "    create_styled_table_png(mean_table, min_values, min_stds, f'formatted_table_rmsa_topology_{i}.png')\n",
    "    print(f\"PNG table for topology {i} has been saved to 'formatted_table_rmsa_topology_{i}.png'\")\n",
    "\n",
    "print(\"\\nAll tables have been saved as PNG images.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f61a299f7f4a5117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T11:26:46.482693Z",
     "start_time": "2024-06-29T11:26:46.303525Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def format_heuristic(heuristic):\n",
    "    return heuristic.upper().replace('_', '-')\n",
    "\n",
    "env_type = \"rwa_lightpath_reuse\"\n",
    "topologies = [\"cost239\", \"nsfnet\"]\n",
    "heuristics = ['ksp_ff', 'ff_ksp']#, 'ksp_mu']#, 'ksp_mu_nonrel', 'ksp_mu_unique', 'mu_ksp', 'mu_ksp_nonrel', 'mu_ksp_unique']\n",
    "num_requests_nsfnet = [1e4, 1e4, 1.5e4, 2e4, 2.5e4]\n",
    "num_requests_cost239 = [2e4, 2e4, 2.5e4, 3e4, 3.5e4]\n",
    "k_range = range(1, 11)\n",
    "tables = []\n",
    "\n",
    "for topology in topologies:\n",
    "    data = []\n",
    "    for heuristic in heuristics:\n",
    "        for k in k_range:\n",
    "            row = []\n",
    "            num_requests_list = num_requests_nsfnet if topology == \"nsfnet\" else num_requests_cost239\n",
    "            for i, num_requests in enumerate(num_requests_list):\n",
    "                first_blocking = True if i == 0 else False\n",
    "                df = read_rwa_lightpath_reuse_files(topology, heuristic, k, num_requests, first_blocking=first_blocking)\n",
    "                accepted_services_mean = df[\"accepted_services\"].mean()\n",
    "                accepted_services_std = np.sqrt(np.sum(df[\"accepted_services_std\"]**2)/len(df))\n",
    "                row.extend([accepted_services_mean, accepted_services_std])\n",
    "            data.append([format_heuristic(heuristic), k] + row)\n",
    "\n",
    "    # Create multi-index DataFrame with titled columns\n",
    "    num_requests_list[0] = \"First Block\"\n",
    "    columns = ['Heuristic', 'k']\n",
    "    for num_requests in num_requests_list:\n",
    "        num_requests = f\"{num_requests/1000:.0f}k\" if num_requests != \"First Block\" else num_requests\n",
    "        columns.extend([(num_requests, 'Accepted Services Mean'), (num_requests, 'Accepted Services Std')])\n",
    "    \n",
    "    table = pd.DataFrame(data, columns=columns)\n",
    "    table = table.set_index(['Heuristic', 'k'])\n",
    "    \n",
    "    # Create a MultiIndex for the columns\n",
    "    table.columns = pd.MultiIndex.from_tuples(table.columns, names=['# Requests', 'Metric'])\n",
    "    \n",
    "    tables.append(table)\n",
    "\n",
    "# Example of how to display the table\n",
    "print(tables[0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27bfb5b503534daa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T11:26:56.579785Z",
     "start_time": "2024-06-29T11:26:56.555183Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def format_table_for_publication(table):\n",
    "    # Function to determine cell color\n",
    "    \n",
    "    def color_cell(value, max_value, max_std):\n",
    "        if pd.isna(value):\n",
    "            return ''\n",
    "        if value >= max_value - max_std:\n",
    "            return 'background-color: green; color: white'\n",
    "        else:\n",
    "            return 'background-color: red; color: white'\n",
    "    \n",
    "    # Create a copy of the table with only BP Mean values\n",
    "    mean_table = table.xs('Accepted Services Mean', axis=1, level='Metric')\n",
    "    \n",
    "    # Find the minimum value and its corresponding std for each load\n",
    "    max_values = mean_table.max()\n",
    "    max_indices = mean_table.idxmax()\n",
    "    max_stds = pd.Series(index=max_values.index)\n",
    "    for num_requests in max_values.index:\n",
    "        max_stds[num_requests] = table.loc[max_indices[num_requests], (num_requests, 'Accepted Services Std')]\n",
    "    \n",
    "    # Apply coloring\n",
    "    styled_table = mean_table.style.apply(lambda col: [color_cell(v, max_values[col.name], max_stds[col.name]) for v in col], axis=0)\n",
    "    \n",
    "    # Format numbers\n",
    "    styled_table = styled_table.format(\"{:.0f}\")\n",
    "    \n",
    "    # Add a caption\n",
    "    #styled_table = styled_table.set_caption(\"Blocking Probability (BP) for different heuristics and loads. Green cells are within one standard deviation of the minimum BP for that load.\")\n",
    "    \n",
    "    return styled_table\n",
    "\n",
    "# Assuming 'tables' is your list of DataFrames, one for each topology\n",
    "for i, table in enumerate(tables):\n",
    "    styled_table = format_table_for_publication(table)\n",
    "    \n",
    "    # Display the table (in a Jupyter notebook this will show the formatted table)\n",
    "    display(styled_table)\n",
    "    \n",
    "    # Save to HTML (you can then copy this into your paper or convert to LaTeX)\n",
    "    styled_table.to_html(f'formatted_table_rwalr_{i}.html')\n",
    "\n",
    "# If you need LaTeX output, you can use a library like pandas_to_latex or manually convert the HTML"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1db0efb4e724bb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-29T11:22:09.333937Z",
     "start_time": "2024-06-29T11:21:57.630473Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def format_table_for_publication(table):\n",
    "    # Create a copy of the table with only BP Mean values\n",
    "    mean_table = table.xs('BP Mean', axis=1, level='Metric')\n",
    "    \n",
    "    # Find the minimum value and its corresponding std for each load\n",
    "    min_values = mean_table.min()\n",
    "    min_indices = mean_table.idxmin()\n",
    "    min_stds = pd.Series(index=min_values.index)\n",
    "    for load in min_values.index:\n",
    "        min_stds[load] = table.loc[min_indices[load], (load, 'BP Std')]\n",
    "    \n",
    "    return mean_table, min_values, min_stds\n",
    "\n",
    "def create_styled_table_png(table, min_values, min_stds, filename, dpi=300):\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(20, len(table) * 0.5))\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Create the table\n",
    "    table_obj = ax.table(cellText=table.values,\n",
    "                         rowLabels=table.index,\n",
    "                         colLabels=table.columns,\n",
    "                         cellLoc='center',\n",
    "                         loc='center')\n",
    "    \n",
    "    # Style the table\n",
    "    table_obj.auto_set_font_size(False)\n",
    "    table_obj.set_fontsize(9)\n",
    "    table_obj.scale(1.2, 1.5)\n",
    "    \n",
    "    # Color the cells\n",
    "    for (row, col), cell in table_obj.get_celld().items():\n",
    "        if row == 0:  # Header\n",
    "            cell.set_facecolor('#4472C4')\n",
    "            cell.set_text_props(color='white')\n",
    "        elif col == -1:  # Row labels\n",
    "            cell.set_facecolor('#4472C4')\n",
    "            cell.set_text_props(color='white')\n",
    "        else:\n",
    "            value = table.iloc[row-1, col]\n",
    "            if value <= min_values[table.columns[col]] + min_stds[table.columns[col]]:\n",
    "                cell.set_facecolor('#C6EFCE')\n",
    "            else:\n",
    "                cell.set_facecolor('#FFC7CE')\n",
    "    \n",
    "    # Add title\n",
    "    plt.title('Blocking Probability (BP) for different heuristics and loads.\\n'\n",
    "              'Green cells are within one standard deviation of the minimum BP for that load.',\n",
    "              fontsize=12, fontweight='bold', pad=20)\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=dpi, bbox_inches='tight', pad_inches=0.5)\n",
    "    plt.close()\n",
    "\n",
    "# Assuming 'tables' is your list of DataFrames, one for each topology\n",
    "for i, table in enumerate(tables):\n",
    "    mean_table, min_values, min_stds = format_table_for_publication(table)\n",
    "    create_styled_table_png(mean_table, min_values, min_stds, f'formatted_table_rwalr_topology_{i}.png')\n",
    "    print(f\"PNG table for topology {i} has been saved to 'formatted_table_rwalr_topology_{i}.png'\")\n",
    "\n",
    "print(\"\\nAll tables have been saved as PNG images.\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316d0a8cf1958d5",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcbd87f22ffc44d",
   "metadata": {},
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# \n",
    "# def plot_blocking_prob_vs_load(table, heuristics, k_values, filename='blocking_prob_vs_load.png'):\n",
    "#     plt.figure(figsize=(12, 8))\n",
    "#     for heuristic in heuristics:\n",
    "#         for k in k_values:\n",
    "#             data = table.loc[heuristic, (k, slice(None), 'mean')]\n",
    "#             plt.plot(load_range, data.values, label=f'{heuristic}, k={k}', marker='o')\n",
    "#     \n",
    "#     plt.xlabel('Load')\n",
    "#     plt.ylabel('Blocking Probability')\n",
    "#     plt.title('Blocking Probability vs Load for Different Heuristics and k Values')\n",
    "#     plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "# \n",
    "# def plot_heatmap(table, filename='blocking_prob_heatmap.png'):\n",
    "#     mean_data = table.xs('mean', level='BP', axis=1)\n",
    "#     plt.figure(figsize=(15, 10))\n",
    "#     sns.heatmap(mean_data, cmap='YlOrRd', annot=True, fmt='.2e', cbar_kws={'label': 'Blocking Probability'})\n",
    "#     plt.title('Heatmap of Blocking Probability for Different Heuristics, k Values, and Loads')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "# \n",
    "# def plot_box_plot(table, filename='blocking_prob_box_plot.png'):\n",
    "#     # Select only the 'mean' values and reset the index\n",
    "#     data_mean = table.xs('mean', level='BP', axis=1).stack().reset_index()\n",
    "#     data_mean.columns = ['Heuristic', 'k', 'load', 'Blocking Probability']\n",
    "#     \n",
    "#     plt.figure(figsize=(15, 8))\n",
    "#     sns.boxplot(x='Heuristic', y='Blocking Probability', data=data_mean)\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.title('Distribution of Blocking Probability for Different Heuristics')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "# \n",
    "# # Usage\n",
    "# for i, table in enumerate(tables):\n",
    "#     plot_blocking_prob_vs_load(table, heuristics[:3], [1, 5, 10], f'blocking_prob_vs_load_{topologies[i]}.png')\n",
    "#     plot_heatmap(table, f'blocking_prob_heatmap_{topologies[i]}.png')\n",
    "#     plot_box_plot(table, f'blocking_prob_box_plot_{topologies[i]}.png')\n",
    "# \n",
    "# # For comparing topologies:\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "# for i, topology in enumerate(topologies):\n",
    "#     mean_data = tables[i].xs('mean', level='BP', axis=1)\n",
    "#     sns.heatmap(mean_data, cmap='YlOrRd', annot=False, cbar_kws={'label': 'Blocking Probability'}, ax=axes[i])\n",
    "#     axes[i].set_title(f'Blocking Probability Heatmap for {topology}')\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
